# ALA Computer vision Demos
This repository contains a collection of computer vision demos using ALA and computer vision (AI) libraries. 

## ðŸš€ Demos
- WildObs Tech Demo 1: ALA v YoloV11 (yolov11)

    - Released 2 months ago, YoloV11 is the newest version of the Yolo object detection algorithm. It is faster and more accurate than the previous versions. We test this new foundational model on echinas and see how it performs ðŸ§¸
    - 1st use the `download_images.R` script to download the images from the ALA API. See why [here](https://github.com/AtlasOfLivingAustralia/galah-python/issues/218)
    - 2nd run the `animal_detector_yolov11.ipynb` script to run the YoloV11 model on the images

- WildObs Tech Demo 2: ALA v Yolo-World (yoloworld)
    - Released earlier in 2024, Yolo-World is a an adaptation of the Yolo object detection algorithm for vision-language queries. The user can use text to ask for the model to detect specific objects in the images without previous training. We test this new model on 3 images of varying complexities and see how it performs

- WildObs Tech Demo 2: ALA v MegaDetector (megadetector) ðŸ”œ

- WildObs Tech Demo 3: ALA v GroundingDino (dino) ðŸ”œ



